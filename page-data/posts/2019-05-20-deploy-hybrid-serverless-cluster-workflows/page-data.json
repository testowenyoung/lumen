{"componentChunkName":"component---src-templates-blog-post-js","path":"/posts/2019-05-20-deploy-hybrid-serverless-cluster-workflows/","result":{"data":{"site":{"siteMetadata":{"title":"Gatsby Starter Blog"}},"markdownRemark":{"id":"03cd04cc-e69f-5697-b5b8-0265077764f7","excerpt":"Serverless infrastructure is becoming ever more popular and a lot of organisations want to benefit from the advantages it provides, such as on demand pricing…","html":"<p>Serverless infrastructure is becoming ever more popular and a lot of organisations want to benefit from the advantages it provides, such as on demand pricing and scalability. Having said that, it may be hard for an organisation to switch completely from VM and container based workflows to serverless based workflows.</p>\n<p>That is why, from my perspective, orchestrators allow us to take the best from both and benefit from the advantages serverless and cluster workflows.</p>\n<p>In this post, I’ll cover a method to build a serverless workflow using AWS Lambda as a Serverless processing node, AWS Fargate and AWS Batch as cluster processing nodes and AWS <a href=\"https://serverless.com/aws-step-functions/\">Step Functions</a> as the orchestrator between them.</p>\n<p>We will cover the following:</p>\n<ul>\n<li>AWS Batch and AWS Fargate: why they are beneficial and what their differences are.</li>\n<li>AWS Step Functions: how it is different from other ways of connecting services and what the advantages are.</li>\n<li>What are some specific cases where hybrid infrastructure could be beneficial</li>\n<li>Example code which allows us to deploy an AWS Lambda and AWS Fargate solution.</li>\n<li>Example code which allows us to deploy an AWS Lambda and AWS Batch solution.</li>\n</ul>\n<h3>AWS Batch and AWS Fargate</h3>\n<p>AWS Batch and AWS Fargate implement a Container-as-a-Service approach: you just need to define a docker image, some CPU/memory resources and you are good to go.</p>\n<p>AWS Batch provides a way to have an on demand ECS cluster which scales according to what you are trying to process. You can use any instance (including GPU) as well as Spot instances, which can save you up to 90% of the cost of on demand instances. The process works in the following way: you send jobs to the jobs queue of AWS Batch and based on the number of jobs it scales the number of instances in the cluster. If the queue is empty it will eventually clear the cluster.</p>\n<p>AWS Fargate, on the other hand, is closer to AWS Lambda in terms of organisation. Every job is executed on a single instance which is created just for this job. So while on one hand Fargate scales a lot faster than Batch (10s of seconds vs minutes), it is limited in terms of types of instances. You can only use CPU instances, but you can customize the amount of memory and vCPU available which can help to reduce the cost.</p>\n<p>So while both Fargate and Batch provide an on-demand cluster experience, they are very different in terms of how it is organised. If you need specific instances (let’s say with GPU), then you will need to use AWS Batch. If you need to have low latency and better scaling, then you will be better off with AWS Fargate.</p>\n<p>While both AWS Batch and AWS Fargate are very convenient services for on demand processing, the real game changer came during Re:Invent 2018 when AWS announced native integration to AWS Step Functions.</p>\n<h3>AWS Step Functions</h3>\n<p>One of the challenges of a microservices architecture is communication between different services. There are three broad methods by which services can communicate:</p>\n<ul>\n<li>through synchronous API requests (for example API Gateway)</li>\n<li>through asynchronous messaging between services (for example SQS and SNS)</li>\n<li>through a state machine orchestrator</li>\n</ul>\n<p>API requests are great for requests that finish quickly with a limited need for parallelism and asynchronous messaging excels in dealing with longer running processes and a large amount of parallelism. But the biggest advantage of an orchestrator is that it enables the complete specification of every step of a workflow, how it is processed, the state of data between each step (making it a state machine), custom error handling and monitoring jobs processing at scale. The biggest disadvantage of an orchestrator is usually either price or the need to deploy it separately as another piece of infrastructure. Which is where Step Functions comes in.</p>\n<p>AWS Step Functions enables us to construct a state machine graph with custom logic, where each processing node can be either AWS Lambda, AWS Batch or AWS Fargate. The Step Function service tracks the completion of the task as well as if an exception occurred. It enables us to branch out logic in case of error (with the ability to customize the handling of an error), execute jobs in parallel and implement retry logic.</p>\n<p>In summary, AWS Step Functions enables us to combine Serverless processing with container based cluster processing via Batch and Fargate, expanding our capabilities and the options available to us.</p>\n<h3>Use cases</h3>\n<h4>Machine learning training pipeline</h4>\n<p>For a machine learning pipeline, we can benefit from the large amount of parallelization AWS Batch or Fargate gives us on our various hyperparameters while still benefitting from storing and comparing results via Serverless Lambda functions</p>\n<p><img src=\"https://s3-us-west-2.amazonaws.com/assets.blog.serverless.com/2019-05-10-deploy_hybrid_serverless_cluster_workflows/Serverless_Graph-machine+learning+training.png\" alt=\"Machine learning training pipeline\"></p>\n<h4>Machine learning deployment pipeline</h4>\n<p>A hybrid infrastructure enables to solve a number of issues which occur during the implementation of a machine learning deployment pipeline:</p>\n<ul>\n<li>A modular approach which enables to combine multiple models and frameworks into one pipeline.</li>\n<li>A/B testing which allows us to compare model performance, to ensure the best model goes into production.</li>\n<li>Scalable inference allows us to run batches in parallel which increases the speed of processing.</li>\n</ul>\n<p><img src=\"https://s3-us-west-2.amazonaws.com/assets.blog.serverless.com/2019-05-10-deploy_hybrid_serverless_cluster_workflows/Serverless_Graph-Machine+learning+deployment.png\" alt=\"Machine learning deployment pipeline\"></p>\n<h4>Data pipeline</h4>\n<p>A data pipeline can utilize hybrid infrastructure to modularize the processing parts into several types of modules. Modules which can be easily parallelized can be processed through AWS Lambdas, modules which need to be processed through GPU instances can use AWS Batch and modules which require long processing times can utilize AWS Fargate.</p>\n<p><img src=\"https://s3-us-west-2.amazonaws.com/assets.blog.serverless.com/2019-05-10-deploy_hybrid_serverless_cluster_workflows/Serverless_Graph-data+pipeline.png\" alt=\"Data pipeline\"></p>\n<h3>Pushing Docker container image to ECR</h3>\n<p>Let’s start with downloading code from the repo. We will create an example docker image and publish it to ECR.</p>\n<p><strong>Prerequisites:</strong> You will need to have docker and AWS CLI installed</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">git</span> clone https://github.com/ryfeus/stepfunctions2processing.git\n\n<span class=\"token builtin class-name\">cd</span> docker\n\ndocker build -t stepfunctiontest <span class=\"token builtin class-name\">.</span>\n\n<span class=\"token variable\"><span class=\"token variable\">$(</span>aws ecr get-login --no-include-email --region us-east-1<span class=\"token variable\">)</span></span>\n\naws ecr create-repository --repository-name stepfunctiontest\n\ndocker tag stepfunctiontest:latest <span class=\"token operator\">&lt;</span>accountid<span class=\"token operator\">></span>.dkr.ecr.us-east-1.amazonaws.com/stepfunctiontest:latest\n\ndocker push <span class=\"token operator\">&lt;</span>accountid<span class=\"token operator\">></span>.dkr.ecr.us-east-1.amazonaws.com/stepfunctiontest:latest</code></pre></div>\n<h3>Example code for AWS Fargate</h3>\n<h4>4 line example</h4>\n<p>Let’s get started with an AWS Fargate example. We’ll use the following stack:</p>\n<ul>\n<li>AWS Lambda and AWS Fargate for processing</li>\n<li>Serverless framework for handling deployment and configuration</li>\n</ul>\n<p>To get started, you’ll need to <a href=\"https://serverless.com/framework/docs/providers/aws/guide/installation/\">have the Serverless Framework installed</a>. </p>\n<p>Run the following commands from the root folder of the cloned repository.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token builtin class-name\">cd</span> aws-fargate\n\n<span class=\"token function\">npm</span> <span class=\"token function\">install</span>\n\nserverless deploy</code></pre></div>\n<p>You’ll receive the following response:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Serverless: Packaging service...\nServerless: Excluding development dependencies...\nServerless: Creating Stack...\nServerless: Checking Stack create progress...\n.....\nServerless: Stack create finished...\nServerless: Uploading CloudFormation file to S3...\nServerless: Uploading artifacts...\nServerless: Uploading service StepFunctionFargate.zip file to S3 (32.58 KB)...\nServerless: Validating template...\nServerless: Updating Stack...\nServerless: Checking Stack update progress...\n......................................................................................................\nServerless: Stack update finished...\nService Information\nservice: StepFunctionFargate\nstage: dev\nregion: us-east-1\nstack: StepFunctionFargate-dev\nresources: 34\napi keys:\n  None\nendpoints:\nfunctions:\n  branch: StepFunctionFargate-dev-branch\n  map: StepFunctionFargate-dev-map\n  reduce: StepFunctionFargate-dev-reduce\nlayers:\n  None\nServerless StepFunctions OutPuts\nendpoints:\n  GET - https://&lt;api-prefix&gt;.execute-api.us-east-1.amazonaws.com/dev/startFunction</code></pre></div>\n<p>Visit the console to confirm your new Step Functions state machine was created (<a href=\"https://console.aws.amazon.com/states/home\">https://console.aws.amazon.com/states/home</a>) and you can invoke it using output endpoint.</p>\n<h4>Code decomposition</h4>\n<p>The configuration file consists of the following parts:</p>\n<ul>\n<li><code class=\"language-text\">functions</code> which contain information about the Lambdas which are used</li>\n<li><code class=\"language-text\">stepFunctions</code> which contains description of the state machine graph</li>\n<li><code class=\"language-text\">resources</code> where AWS Fargate is defined. You can adjust the parameters section to adapt the config to your needs.</li>\n</ul>\n<h3>Example code for AWS Batch</h3>\n<h4>4 line example</h4>\n<p>Let’s get started with AWS Batch example. We’ll use the following stack:</p>\n<ul>\n<li>AWS Lambda and AWS Batch for processing</li>\n<li>Serverless framework for handling deployment and configuration</li>\n</ul>\n<p>To get started, you’ll need to <a href=\"https://serverless.com/framework/docs/providers/aws/guide/installation/\">have the Serverless Framework installed</a>. </p>\n<p>Run the following commands from the root folder of the cloned repository.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token builtin class-name\">cd</span> aws-batch\n\n<span class=\"token function\">npm</span> <span class=\"token function\">install</span>\n\nserverless deploy</code></pre></div>\n<p>You’ll receive the following response:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Serverless: Packaging service...\nServerless: Excluding development dependencies...\nServerless: Creating Stack...\nServerless: Checking Stack create progress...\n.....\nServerless: Stack create finished...\nServerless: Uploading CloudFormation file to S3...\nServerless: Uploading artifacts...\nServerless: Uploading service StepFuncBatch.zip file to S3 (33.21 KB)...\nServerless: Validating template...\nServerless: Updating Stack...\nServerless: Checking Stack update progress...\n.......................................................................................\nServerless: Stack update finished...\nService Information\nservice: StepFuncBatch\nstage: dev\nregion: us-east-1\nstack: StepFuncBatch-dev\nresources: 29\napi keys:\n  None\nendpoints:\nfunctions:\n  branch: StepFuncBatch-dev-branch\n  map: StepFuncBatch-dev-map\n  reduce: StepFuncBatch-dev-reduce\nlayers:\n  None\nServerless StepFunctions OutPuts\nendpoints:\n  GET - https://&lt;api-prefix&gt;.execute-api.us-east-1.amazonaws.com/dev/startFunction</code></pre></div>\n<p>Visit the console to confirm your new Step Functions state machine was created (<a href=\"https://console.aws.amazon.com/states/home\">https://console.aws.amazon.com/states/home</a>) and you can invoke it using output endpoint.</p>\n<h4>Code decomposition</h4>\n<p>Configuration file consists of the following parts:</p>\n<ul>\n<li><code class=\"language-text\">functions</code> which contains information about Lambdas which are used</li>\n<li><code class=\"language-text\">stepFunctions</code> which contains description of the execution graph</li>\n<li><code class=\"language-text\">resources</code> where AWS Batch is defined. You can adjust the parameters section to adapt the config to your needs.</li>\n</ul>\n<h3>Conclusion</h3>\n<p>We’ve created two processing workflows with AWS Step functions, AWS Batch, AWS Fargate and AWS Lambda via the Serverless Framework. Setting everything up was extremely easy, and saved us a lot of time. By modifying the serverless YAML file, you can change configuration of state machine graph to accomplish whichever task you need.</p>\n<p>Feel free to check the project repository at <a href=\"https://github.com/ryfeus/stepfunctions2processing\">https://github.com/ryfeus/stepfunctions2processing</a>.</p>\n<p>I’m excited to see how others are using Serverless to empower their development. Feel free to drop me a line in the comments, and happy developing!</p>","frontmatter":{"title":"Using the Serverless framework to deploy hybrid serverless/cluster workflows","date":"May 20, 2019","description":"We’ll cover how to use Serverless Framework, AWS Lambda, AWS Step Functions, AWS Fargate and AWS Batch to deploy hybrid serverless/cluster workflows."}}},"pageContext":{"slug":"/posts/2019-05-20-deploy-hybrid-serverless-cluster-workflows/","previous":{"fields":{"slug":"/posts/2019-05-14-s3-one-time-signed-url/"},"frontmatter":{"title":"Uploading objects to S3 using one-time pre signed URLs"}},"next":{"fields":{"slug":"/posts/2019-05-22-deployment-profiles/"},"frontmatter":{"title":"Serverless Framework Enterprise 0.10.0 - Deployment Profiles"}}}}}